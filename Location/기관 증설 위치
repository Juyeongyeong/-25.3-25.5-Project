## í•„ìš”ì§€ìˆ˜ êµ¬í•˜ê¸°
import json
import folium
import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler

# 1. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
# ê¸°ê´€ ë°ì´í„°
agencies_df = pd.read_csv('abcd.csv', low_memory=False)
seoul_agencies = agencies_df.query('íŠ¹ë³„ì‹œë„ == "ì„œìš¸íŠ¹ë³„ì‹œ"')

# êµ¬ë³„ ê¸°ê´€ ìˆ˜ ì§‘ê³„
seoul_agency_count = seoul_agencies.groupby('ì§€ì—­').size().to_frame().reset_index()
seoul_agency_count.columns = ['êµ¬', 'ê¸°ê´€ìˆ˜']

#  "ì„œìš¸íŠ¹ë³„ì‹œ " ì œê±°í•˜ì—¬ ë³‘í•© ë¬¸ì œ í•´ê²°
seoul_agency_count['êµ¬'] = seoul_agency_count['êµ¬'].str.replace('ì„œìš¸íŠ¹ë³„ì‹œ ', '', regex=True)

# ì¸êµ¬ë°€ë„ ë°ì´í„°
population_df = pd.read_csv('ì¸êµ¬ë°€ë„.csv')
population_df = population_df.rename(columns={'ì§€ì—­': 'êµ¬', 'ì¸êµ¬': 'ì¸êµ¬ìˆ˜', 'ì¸êµ¬ë°€ë„': 'ì¸êµ¬ë°€ë„'})[['êµ¬', 'ì¸êµ¬ë°€ë„']]

# ê¸°ì´ˆì—°ê¸ˆ ë°ì´í„°
pension_df = pd.read_csv('ê¸°ì´ˆì—°ê¸ˆ.csv')
pension_df = pension_df.rename(columns={'ì‹œêµ°êµ¬': 'êµ¬'})
pension_df['í•©ê³„'] = pension_df['í•©ê³„'].str.replace(',', '').astype(int)

# 2. ë°ì´í„° ë³‘í•©
merged_df = pd.merge(seoul_agency_count, population_df, on='êµ¬', how='outer')

analysis_df = pd.merge(
    merged_df,
    pension_df[['êµ¬', 'í•©ê³„']].rename(columns={'í•©ê³„': 'ê¸°ì´ˆì—°ê¸ˆìˆ˜ê¸‰ì'}),
    on='êµ¬',
    how='outer'
)

# 3. ë°ì´í„° ì •ê·œí™”
numeric_cols = ['ê¸°ê´€ìˆ˜', 'ì¸êµ¬ë°€ë„', 'ê¸°ì´ˆì—°ê¸ˆìˆ˜ê¸‰ì']
analysis_df[numeric_cols] = analysis_df[numeric_cols].fillna(0)

scaler = MinMaxScaler()
analysis_df[numeric_cols] = scaler.fit_transform(analysis_df[numeric_cols])

# 4. ê°€ì¤‘ì¹˜ ì¡°ì • (2027ë…„ ê¸°ì¤€ ë°˜ì˜) (ê³µì‹ì€ ì €í¬ê°€ ì…ë ¥í•œê±°ê³  ê¸°ê´€ìˆ˜ ê°€ì¤‘ì¹˜ë¥¼ ì—†ì• ë„, ë” ì¤˜ë„ ë¬´ê´€í•©ë‹ˆë‹¹)
analysis_df['í•„ìš”ì§€ìˆ˜'] = (
    analysis_df['ê¸°ì´ˆì—°ê¸ˆìˆ˜ê¸‰ì'] * 0.60 +  # ê³µìµí˜• 60%
    analysis_df['ì¸êµ¬ë°€ë„'] * 0.40 -         # ì‚¬íšŒì„œë¹„ìŠ¤í˜•+ë¯¼ê°„í˜• 40%
    analysis_df['ê¸°ê´€ìˆ˜'] * 0.3             # ê¸°ê´€ìˆ˜ê°€ ë§ì„ìˆ˜ë¡ ì˜í–¥ì€ ìˆì§€ë§Œ ì•½í•˜ê²Œ
)

# 5. ìµœì¢… ê²°ê³¼ ì¶œë ¥
print("ğŸš€ ìµœì¢… í•„ìš” ì§€ìˆ˜ ìƒìœ„ 5ê°œ êµ¬:")
result = analysis_df.sort_values('í•„ìš”ì§€ìˆ˜', ascending=False).head(5)[['êµ¬', 'í•„ìš”ì§€ìˆ˜', 'ê¸°ê´€ìˆ˜']]
print(result.round(4))


# 4. ì§€ë„ ì‹œê°í™” ê°œì„ 
# ì„œìš¸ì‹œ êµ¬ë³„ ê²½ê³„ ë°ì´í„°
geo_path = 'ì„œìš¸ì‹œ êµ¬ë³„ ê²½ê³„ ë°ì´í„°.json'
geo_json = json.load(open(geo_path, encoding='utf-8'))

# ê¸°ì¡´ ìš´ì˜ê¸°ê´€ ìœ„ì¹˜ ë°ì´í„°
df = pd.read_csv('abcd.csv', low_memory=False)
data = df.query('íŠ¹ë³„ì‹œë„ == "ì„œìš¸íŠ¹ë³„ì‹œ"')

# ê¸°ë³¸ ì§€ë„ ì„¤ì •
f = folium.Figure(width=700, height=500)
m = folium.Map(location=[37.566535, 126.9779692], zoom_start=11).add_to(f)

# í•„ìš”ì§€ìˆ˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ Choropleth ìƒì„±
choropleth = folium.Choropleth(
    geo_data=geo_json,
    data=analysis_df,
    columns=['êµ¬', 'í•„ìš”ì§€ìˆ˜'],
    key_on='feature.properties.name',
    fill_color='YlOrRd',
    fill_opacity=0.7,
    line_opacity=0.7,
    legend_name='ì„œìš¸ì‹œ êµ¬ë³„ êµ­ë¯¼ì·¨ì—…ì œë„ í•„ìš”ì§€ìˆ˜'
).add_to(m)

# êµ¬ë³„ ì´ë¦„ íˆ´íŒ ì¶”ê°€ ( ë§ˆìš°ìŠ¤ ì˜¬ë¦¬ë©´ ê¸€ì”¨ ë‚˜íƒ€ë‚˜ëŠ” ê¸°ëŠ¥ )
choropleth.geojson.add_child(
    folium.features.GeoJsonTooltip(
        fields=['name'], 
        aliases=['êµ¬ ì´ë¦„:'],
        sticky=True
    )
)

# ê¸°ì¡´ ìš´ì˜ê¸°ê´€ ìœ„ì¹˜ ë§ˆì»¤ ì¶”ê°€ : ì§€ë„ ì¶œë ¥ì „ì— ë„£ìœ¼ë©´ ë¨
for _, row in data.iterrows():
    folium.Marker(
        location=[row['ìœ„ë„'], row['ê²½ë„']],
        popup=row['ê¸°ê´€ëª…'],
        icon=folium.Icon(color='blue', icon='info-sign')
    ).add_to(m)

# ì§€ë„ ì¶œë ¥
m
