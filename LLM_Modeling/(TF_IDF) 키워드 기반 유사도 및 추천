import requests
from bs4 import BeautifulSoup
import sqlite3
import time

# ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ë° í…Œì´ë¸” ìƒì„±
conn = sqlite3.connect("books.db")
cursor = conn.cursor()

cursor.execute("""
CREATE TABLE IF NOT EXISTS books (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    title TEXT,
    link TEXT,
    subtitle TEXT,
    edition TEXT,
    author TEXT,
    publisher TEXT,
    pub_date TEXT,
    discount TEXT,
    price TEXT,
    original_price TEXT,
    point TEXT,
    rating TEXT,
    review_count TEXT,
    summary TEXT,
    tags TEXT
)
""")
conn.commit()

# í¬ë¡¤ë§ íŒŒë¼ë¯¸í„° ì„¤ì •
disp_no = "001001003031"  # ê²½ì œ/ê²½ì˜ ì¹´í…Œê³ ë¦¬
start_page = 1
end_page = 5  # ì›í•˜ëŠ” í˜ì´ì§€ ë²”ìœ„ë¡œ ì„¤ì •
headers = {"User-Agent": "Mozilla/5.0"}

for page in range(start_page, end_page + 1):
    print(f"ğŸ“„ í˜ì´ì§€ {page} ìˆ˜ì§‘ ì¤‘...")

    url = "https://www.yes24.com/product/category/CategoryProductContents"
    params = {
        "dispNo": disp_no,
        "order": "SINDEX_ONLY",
        "addOptionTp": "0",
        "page": page,
        "size": 24,
        "statGbYn": "N",
        "viewMode": "",
        "_options": "",
        "directDelvYn": "",
        "usedTp": "0",
        "elemNo": "0",
        "elemSeq": "0",
        "seriesNumber": "0"
    }

    res = requests.get(url, params=params, headers=headers)
    soup = BeautifulSoup(res.text, "html.parser")
    items = soup.select(".item_info")

    if not items:
        print("âŒ ë” ì´ìƒ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        break

    for item in items:
        title_tag = item.select_one(".info_name .gd_name")
        title = title_tag.get_text(strip=True) if title_tag else None
        link = "https://www.yes24.com" + title_tag['href'] if title_tag else None

        subtitle = item.select_one(".info_name .gd_nameE")
        edition = item.select_one(".info_name .gd_feature")
        author_tag = item.select_one(".info_auth a")
        publisher_tag = item.select_one(".info_pub a")
        pub_date = item.select_one(".info_date")
        discount = item.select_one(".txt_sale em")
        price = item.select_one(".txt_num .yes_b")
        original_price = item.select_one(".txt_num.dash .yes_m")
        point = item.select_one(".yPoint")
        rating = item.select_one(".rating_grade .yes_b")
        review_count = item.select_one(".rating_rvCount em.txC_blue")
        summary = item.select_one(".info_read")
        tags = [tag.get_text(strip=True) for tag in item.select(".info_tag .tag a")]

        # DBì— ì‚½ì…
        cursor.execute("""
        INSERT INTO books (
            title, link, subtitle, edition, author, publisher, pub_date,
            discount, price, original_price, point, rating, review_count,
            summary, tags
        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        """, (
            title,
            link,
            subtitle.get_text(strip=True) if subtitle else "",
            edition.get_text(strip=True) if edition else "",
            author_tag.get_text(strip=True) if author_tag else "",
            publisher_tag.get_text(strip=True) if publisher_tag else "",
            pub_date.get_text(strip=True) if pub_date else "",
            discount.get_text(strip=True) + "%" if discount else "",
            price.get_text(strip=True) if price else "",
            original_price.get_text(strip=True) if original_price else "",
            point.get_text(strip=True) if point else "",
            rating.get_text(strip=True) if rating else "",
            review_count.get_text(strip=True) if review_count else "",
            summary.get_text(strip=True) if summary else "",
            ", ".join(tags)
        ))

    conn.commit()
    time.sleep(1)  # ì„œë²„ ë¶€í•˜ ë°©ì§€

# ì¢…ë£Œ
conn.close()
print("âœ… ëª¨ë“  ë„ì„œ ì •ë³´ë¥¼ books.dbì— ì €ì¥ ì™„ë£Œ")

#====
# prompt: ìˆ˜ì§‘í•œ db íŒŒì¼ì„ ì½ì–´ì™€ì„œ df ë³€ìˆ˜ë¡œ ë§Œë“¤ê³  ì¤‘ë³µë°ì´í„°ë¥¼ ì œê±°í•˜ê³  ì œëª©, ì„¤ëª…, íƒœê·¸ë¥¼ ê³µë°±ì„ ê¸°ì¤€ìœ¼ë¡œ í•˜ë‚˜ì˜ ë³€ìˆ˜ë¡œ ë§Œë“¤ì–´ì„œ TF-IDF ë¡œ ë²¡í„°í™” í•˜ê³  ì£¼ìš” í‚¤ì›Œë“œ 200ê°œ ì¶”ì¶œ

import sqlite3
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer

# ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
conn = sqlite3.connect('books.db')
df = pd.read_sql_query("SELECT * FROM books", conn)
conn.close()

# ì¤‘ë³µ ë°ì´í„° ì œê±°
df.drop_duplicates(inplace=True)

# ì œëª©, ì„¤ëª…, íƒœê·¸ë¥¼ í•˜ë‚˜ì˜ ì—´ë¡œ í•©ì¹˜ê¸°
df['text'] = df['title'].fillna('') + ' ' + df['summary'].fillna('') + ' ' + df['tags'].fillna('')

# TF-IDF ë²¡í„°í™”
tfidf = TfidfVectorizer()
tfidf_matrix = tfidf.fit_transform(df['text'])

#===
# prompt: # ì£¼ìš” í‚¤ì›Œë“œ ì¶”ì¶œ (ìƒìœ„ 200ê°œ)
# feature_names = tfidf.get_feature_names_out()
# top_keywords = []
# for i in range(tfidf_matrix.shape[0]):
#   scores = tfidf_matrix[i].toarray()[0]
#   sorted_indices = scores.argsort()[::-1][:200]  # ìƒìœ„ 200ê°œ ì¸ë±ìŠ¤
#   keywords = [feature_names[idx] for idx in sorted_indices]
#   top_keywords.extend(keywords)
# # ìƒìœ„ í‚¤ì›Œë“œ ì¶œë ¥ (ì¤‘ë³µ ì œê±°)
# print(set(top_keywords))
# í•´ë‹¹ ì½”ë“œ ë¦¬íŒ©í† ë§í•´ì„œ ê°€ì¤‘ì¹˜ë„ í•¨ê»˜ ì¶œë ¥í•˜ê²Œ ë‹¤ì‹œ ì‘ì„±í•˜ê³  txt íŒŒì¼ë¡œ ì €ì¥

import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer

# ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
conn = sqlite3.connect('books.db')
df = pd.read_sql_query("SELECT * FROM books", conn)
conn.close()

# ì¤‘ë³µ ë°ì´í„° ì œê±°
df.drop_duplicates(inplace=True)

# ì œëª©, ì„¤ëª…, íƒœê·¸ë¥¼ í•˜ë‚˜ì˜ ì—´ë¡œ í•©ì¹˜ê¸°
df['text'] = df['title'].fillna('') + ' ' + df['summary'].fillna('') + ' ' + df['tags'].fillna('')

# TF-IDF ë²¡í„°í™”
tfidf = TfidfVectorizer()
tfidf_matrix = tfidf.fit_transform(df['text'])

# ì£¼ìš” í‚¤ì›Œë“œ ì¶”ì¶œ (ìƒìœ„ 200ê°œ) ë° ê°€ì¤‘ì¹˜ ì¶œë ¥
feature_names = tfidf.get_feature_names_out()
top_keywords = []

with open('top_keywords_with_weights.txt', 'w', encoding='utf-8') as f:
    for i in range(tfidf_matrix.shape[0]):
        scores = tfidf_matrix[i].toarray()[0]
        sorted_indices = scores.argsort()[::-1][:200]  # ìƒìœ„ 200ê°œ ì¸ë±ìŠ¤
        for idx in sorted_indices:
            keyword = feature_names[idx]
            weight = scores[idx]
            top_keywords.append((keyword, weight))
            f.write(f"{keyword}\t{weight}\n")

print("âœ… í‚¤ì›Œë“œì™€ ê°€ì¤‘ì¹˜ ì •ë³´ê°€ top_keywords_with_weights.txt íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

#===
# prompt: ìœ„ ë°ì´í„°ì—ì„œ ìœ ì‚¬ë„ë¥¼ êµ¬í•˜ê³  ëœë¤í•˜ê²Œ 5ê°œì˜ ì±… ì œëª©ì„ ê³¨ë¼ì„œ í•´ë‹¹ ì±…ê³¼ ê°€ì¥ ìœ ì‚¬ë„ê°€ ë†’ì€ ì±… ì œëª© 5ê°œì”© ì¶œë ¥í•˜ê³  ìœ ì‚¬ë„ë„ í•¨ê»˜ ì¶œë ¥í•  ê²ƒ

import pandas as pd
from sklearn.metrics.pairwise import cosine_similarity
import random

# ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° (ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼)
conn = sqlite3.connect('books.db')
df = pd.read_sql_query("SELECT * FROM books", conn)
conn.close()

# ì¤‘ë³µ ë°ì´í„° ì œê±° (ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼)
df.drop_duplicates(inplace=True)

# ì œëª©, ì„¤ëª…, íƒœê·¸ë¥¼ í•˜ë‚˜ì˜ ì—´ë¡œ í•©ì¹˜ê¸° (ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼)
df['text'] = df['title'].fillna('') + ' ' + df['summary'].fillna('') + ' ' + df['tags'].fillna('')

# TF-IDF ë²¡í„°í™” (ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼)
tfidf = TfidfVectorizer()
tfidf_matrix = tfidf.fit_transform(df['text'])

# ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
cosine_similarities = cosine_similarity(tfidf_matrix)

# ëœë¤í•˜ê²Œ 5ê°œì˜ ì±… ì œëª© ì„ íƒ
random_book_indices = random.sample(range(len(df)), 5)

for book_index in random_book_indices:
    # í˜„ì¬ ì±… ì œëª©
    book_title = df['title'].iloc[book_index]
    print(f"ì±… ì œëª©: {book_title}")

    # í˜„ì¬ ì±…ê³¼ ë‹¤ë¥¸ ì±…ë“¤ì˜ ìœ ì‚¬ë„
    similarities = cosine_similarities[book_index]

    # ìœ ì‚¬ë„ê°€ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬ (ìê¸° ìì‹  ì œì™¸)
    similar_books_indices = similarities.argsort()[::-1][1:6]  # ìƒìœ„ 5ê°œ ì¶”ì¶œ (ìê¸° ìì‹  ì œì™¸)

    # ìœ ì‚¬í•œ ì±… ì œëª©ê³¼ ìœ ì‚¬ë„ ì¶œë ¥
    for similar_book_index in similar_books_indices:
        similar_book_title = df['title'].iloc[similar_book_index]
        similarity_score = similarities[similar_book_index]
        print(f"  - {similar_book_title} (ìœ ì‚¬ë„: {similarity_score:.4f})")

    print("-" * 30)

#===
# prompt: cosine_similarities í•´ë‹¹ ë³€ìˆ˜ë¥¼ íˆíŠ¸ë§µìœ¼ë¡œ ì‹œê°í™”

import matplotlib.pyplot as plt
import seaborn as sns

# íˆíŠ¸ë§µ ì‹œê°í™”
plt.figure(figsize=(10, 8))
sns.heatmap(cosine_similarities, annot=False, cmap='viridis')
plt.title('Cosine Similarities Heatmap')
plt.xlabel('Book Index')
plt.ylabel('Book Index')
plt.show()

#===
pd.Series(cosine_similarities[5]).nlargest(10)
#===
book_index = 100
# í˜„ì¬ ì±… ì œëª©
book_title = df['title'].iloc[book_index]
print(f"ì±… ì œëª©: {book_title}")

# í˜„ì¬ ì±…ê³¼ ë‹¤ë¥¸ ì±…ë“¤ì˜ ìœ ì‚¬ë„
similarities = cosine_similarities[book_index]

# ìœ ì‚¬ë„ê°€ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬ (ìê¸° ìì‹  ì œì™¸)
similar_books_indices = similarities.argsort()[::-1][1:6]  # ìƒìœ„ 5ê°œ ì¶”ì¶œ (ìê¸° ìì‹  ì œì™¸)

# ìœ ì‚¬í•œ ì±… ì œëª©ê³¼ ìœ ì‚¬ë„ ì¶œë ¥
for similar_book_index in similar_books_indices:
    similar_book_title = df['title'].iloc[similar_book_index]
    similarity_score = similarities[similar_book_index]
    print(f"  - {similar_book_title} (ìœ ì‚¬ë„: {similarity_score:.4f})")

print("-" * 30

#ì±… ì œëª©: ì‹¤ë¦¬ì½˜ë°¸ë¦¬ì—ì„œ í†µí•˜ëŠ” íŒŒì´ì¬ ì¸í„°ë·° ê°€ì´ë“œ
  - ì†Œí”„íŠ¸ì›¨ì–´ í…ŒìŠ¤íŠ¸ ì „ë¬¸ê°€(CSTS) ê°€ì´ë“œ (ìœ ì‚¬ë„: 0.0961)
  - ëª¨ë˜ ì†Œí”„íŠ¸ì›¨ì–´ ì—”ì§€ë‹ˆì–´ë§ (ìœ ì‚¬ë„: 0.0841)
  - ì œí’ˆì˜ íƒ„ìƒ (ìœ ì‚¬ë„: 0.0720)
  - ì´ê²ƒì´ ì·¨ì—…ì„ ìœ„í•œ ì»´í“¨í„° ê³¼í•™ì´ë‹¤ with CS ê¸°ìˆ  ë©´ì ‘ (ìœ ì‚¬ë„: 0.0664)
  - ì¼ë‹¨ í•´ë³´ë¼êµ¬ìš”? UX (ìœ ì‚¬ë„: 0.0662)
